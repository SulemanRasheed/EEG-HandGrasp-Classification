{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical BCI Challenge-WCCI2020\n",
    "- [website link](https://sites.google.com/view/bci-comp-wcci/?fbclid=IwAR37WLQ_xNd5qsZvktZCT8XJerHhmVb_bU5HDu69CnO85DE3iF0fs57vQ6M)\n",
    "\n",
    "\n",
    " - [Dataset Link](https://github.com/5anirban9/Clinical-Brain-Computer-Interfaces-Challenge-WCCI-2020-Glasgow)\n",
    " \n",
    " \n",
    " - [Braindecode Tutorial](https://braindecode.org/auto_examples/plot_bcic_iv_2a_moabb_trial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, LeaveOneGroupOut, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n",
    "[Mike Cohen Tutorials link for EEG Preprocessing](https://www.youtube.com/watch?v=uWB5tjhataY&list=PLn0OLiymPak2gDD-VDA90w9_iGDgOOb2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Append Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mne_epochs_complete(files_paths, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    similar to get_mne_epochs, just appends data from all relevant files together to give a single\n",
    "    epoch object\n",
    "    '''\n",
    "    eeg_data = []\n",
    "    for filepath in files_paths:\n",
    "        mat_data = loadmat(filepath)\n",
    "        eeg_data.extend(mat_data['RawEEGData'])\n",
    "\n",
    "    idx_start = fs*t_start      # fs*ts\n",
    "    eeg_data = np.array(eeg_data)\n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) # required be ICA, (7-30 Hz) later\n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        labels = []\n",
    "        for filepath in files_paths:\n",
    "            mat_data = loadmat(filepath)\n",
    "            labels.extend(mat_data['Labels'].ravel() - 1)\n",
    "        epochs.event_id = event_id\n",
    "        epochs.events[:,2] = labels    \n",
    "    return epochs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading with Band Pass Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading relevant files\n",
    "training_epochs_all = get_mne_epochs_complete(training_files).filter(7,32) # for all training subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (640, 12, 3072) \t Shape of Labels:  (640,)\n"
     ]
    }
   ],
   "source": [
    "epochs = training_epochs_all.copy()\n",
    "data, labels = epochs.get_data(), epochs.events[:,-1]\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 1 sec stride (using leave one group out cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = training_epochs_all.copy()\n",
    "epochs = epochs.crop(tmin=0.5, tmax=4.5, include_tmax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "# convert epochs to braindecode compatible datastructure \n",
    "# 2sec windows with 0.125 sec stride\n",
    "window_size = 1024 #1024 #1024 #50 # 3072\n",
    "window_stride = 512 #512 #256 # 50\n",
    "\n",
    "windows_datasets = create_from_mne_epochs(\n",
    "            [epochs], # expects list of epochs\n",
    "            window_size_samples = window_size,\n",
    "            window_stride_samples = window_stride,\n",
    "            drop_last_window = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows_datasets_labels(windows_dataset):\n",
    "    labels = []\n",
    "    for i in range(len(windows_dataset.datasets)):\n",
    "        labels.extend(windows_dataset.datasets[i].y)\n",
    "    return np.array(labels) \n",
    "\n",
    "windows_datasets.description = pd.DataFrame(data=get_windows_datasets_labels(windows_datasets), \n",
    "                                           columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Windows in a whole Dataset:  1920\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Windows in a whole Dataset: \", len(windows_datasets.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil.preprocess import exponential_moving_standardize\n",
    "from braindecode.datautil.preprocess import MNEPreproc, NumpyPreproc, preprocess\n",
    "\n",
    "low_cut_hz = 8.  # low cut frequency for filtering\n",
    "high_cut_hz = 32.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        epochs._data[i] = exponential_moving_standardize(data[i], \n",
    "                        factor_new=factor_new, init_block_size=init_block_size)\n",
    "    return epochs\n",
    "\n",
    "preprocessors = [\n",
    "    # keep only EEG sensors\n",
    "    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\n",
    "    # bandpass filter\n",
    "    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "    # exponential moving standardization\n",
    "    MNEPreproc(fn=custom_exp_moving_std_fn, factor_new=factor_new,\n",
    "        init_block_size=init_block_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(windows_datasets, preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #25 #25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = windows_datasets[0][0].shape[0]\n",
    "input_window_samples = windows_datasets[0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples = window_size, #input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = LeaveOneGroupOut()\n",
    "# group parameter for leave one group out cross validation in sklearn, each subject is given unique identifier\n",
    "group_list = []\n",
    "for subject in np.linspace(1,8,8):\n",
    "    group_list.extend([subject for _ in range(len(windows_datasets)//8)]) #since total 8 subjects\n",
    "groups = np.array(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 1 * 0.02 #0.01 \n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "clf =  EEGClassifier(\n",
    "                    model,\n",
    "                    criterion=torch.nn.NLLLoss,\n",
    "                    optimizer=torch.optim.AdamW,\n",
    "                    #iterator_train = StratifiedShuffleSplit(),#cv.split(epochs, y=labels, groups=groups), \n",
    "                    #train_split=predefined_split(train_set),  # using valid_set for validation\n",
    "                    #train_split = cv.split(epochs, y=labels, groups=groups),\n",
    "                    train_split = skorch.dataset.CVSplit(cv=cv.split(windows_datasets, \n",
    "                          y=windows_datasets.description.labels, groups=groups)),\n",
    "                    \n",
    "    \n",
    "                    #= skorch.dataset.CVSplit(cv=LeaveOneGroupOut())),\n",
    "                    optimizer__lr=lr,\n",
    "                    optimizer__weight_decay=weight_decay,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[\n",
    "                        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "                    ],\n",
    "                    device=device,\n",
    "        \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(windows_datasets, n_epochs=25):\n",
    "    print('\\n', '#'*25, 'Cross Subject Training:', '#'*25, '\\n')\n",
    "    dataset = windows_datasets\n",
    "    clf.fit(dataset, y=dataset.description.labels, epochs=n_epochs);\n",
    "    best_validation_acc = clf.callbacks_[4][1].best_score_ # a hack to get best validation accuracy\n",
    "    best_validation_kappa = (2*best_validation_acc)-1\n",
    "    print(\"Best Cross Validation Kappa Score: {:.2f}\".format(best_validation_kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### Cross Subject Training: ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.7464\u001b[0m        \u001b[32m0.7048\u001b[0m            \u001b[35m0.6792\u001b[0m        \u001b[31m0.7166\u001b[0m  0.0200  13.4470\n",
      "      2            0.7417        \u001b[32m0.5835\u001b[0m            0.6375        1.0621  0.0199  11.6820\n",
      "      3            0.6690        \u001b[32m0.5554\u001b[0m            0.5833        1.4334  0.0197  11.2570\n",
      "      4            \u001b[36m0.7833\u001b[0m        \u001b[32m0.5153\u001b[0m            \u001b[35m0.7083\u001b[0m        \u001b[31m0.5871\u001b[0m  0.0192  13.7350\n",
      "      5            \u001b[36m0.7976\u001b[0m        0.5472            0.6833        0.6751  0.0187  13.5100\n",
      "      6            0.5304        \u001b[32m0.4833\u001b[0m            0.5292        1.1845  0.0179  12.6870\n",
      "      7            0.7173        0.4993            0.6667        0.7118  0.0171  14.0700\n",
      "      8            0.7554        0.4903            \u001b[35m0.7417\u001b[0m        \u001b[31m0.5515\u001b[0m  0.0161  13.0450\n",
      "      9            \u001b[36m0.8321\u001b[0m        \u001b[32m0.4565\u001b[0m            \u001b[35m0.7458\u001b[0m        \u001b[31m0.5326\u001b[0m  0.0150  13.3260\n",
      "     10            0.7173        0.4721            0.6417        0.9983  0.0138  12.2680\n",
      "     11            \u001b[36m0.8375\u001b[0m        0.4767            \u001b[35m0.7708\u001b[0m        \u001b[31m0.4951\u001b[0m  0.0126  11.6770\n",
      "     12            \u001b[36m0.8542\u001b[0m        \u001b[32m0.4221\u001b[0m            0.7667        0.5160  0.0113  12.4400\n",
      "     13            0.7964        \u001b[32m0.3969\u001b[0m            0.7375        0.5653  0.0100  15.0260\n",
      "     14            0.6321        0.4023            0.5667        0.8100  0.0087  15.1436\n",
      "     15            0.8280        \u001b[32m0.3853\u001b[0m            0.7625        0.5356  0.0074  13.0690\n",
      "     16            0.8363        \u001b[32m0.3852\u001b[0m            0.6750        0.7383  0.0062  13.1960\n",
      "     17            \u001b[36m0.8679\u001b[0m        \u001b[32m0.3688\u001b[0m            0.7667        0.5504  0.0050  15.1390\n",
      "     18            0.7500        \u001b[32m0.3602\u001b[0m            0.6792        0.6329  0.0039  14.6470\n",
      "     19            \u001b[36m0.8946\u001b[0m        \u001b[32m0.3339\u001b[0m            0.7583        0.5552  0.0029  14.4310\n",
      "     20            \u001b[36m0.8994\u001b[0m        0.3426            0.7667        0.5394  0.0021  12.0300\n",
      "     21            0.8881        \u001b[32m0.3272\u001b[0m            0.7625        0.5293  0.0013  12.7590\n",
      "     22            \u001b[36m0.9071\u001b[0m        \u001b[32m0.3141\u001b[0m            0.7625        0.5506  0.0008  13.1850\n",
      "     23            \u001b[36m0.9095\u001b[0m        \u001b[32m0.3046\u001b[0m            0.7583        0.5559  0.0003  13.7220\n",
      "     24            \u001b[36m0.9101\u001b[0m        0.3074            0.7583        0.5602  0.0001  13.7420\n",
      "     25            \u001b[36m0.9107\u001b[0m        0.3077            0.7542        0.5636  0.0000  13.6310\n",
      "Best Cross Validation Kappa Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "training_function(windows_datasets, n_epochs=n_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
