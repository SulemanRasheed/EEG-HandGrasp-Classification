{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical BCI Challenge-WCCI2020\n",
    "- [website link](https://sites.google.com/view/bci-comp-wcci/?fbclid=IwAR37WLQ_xNd5qsZvktZCT8XJerHhmVb_bU5HDu69CnO85DE3iF0fs57vQ6M)\n",
    "\n",
    "\n",
    " - [Dataset Link](https://github.com/5anirban9/Clinical-Brain-Computer-Interfaces-Challenge-WCCI-2020-Glasgow)\n",
    " \n",
    " \n",
    " - [Braindecode Tutorial](https://braindecode.org/auto_examples/plot_bcic_iv_2a_moabb_trial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n",
    "[Mike Cohen Tutorials link for EEG Preprocessing](https://www.youtube.com/watch?v=uWB5tjhataY&list=PLn0OLiymPak2gDD-VDA90w9_iGDgOOb2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 8, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# although we have evaluation files but their labels aren't opensource so we won't use them here\n",
    "all_files        = glob.glob(data_path + '/*.mat')\n",
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "evaluation_files = glob.glob(data_path + '/*E.mat')\n",
    "len(all_files), len(training_files), len(evaluation_files)     # if these return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have modified the labels values from [1, 2] to [0, 1] as pytorch \n",
    "# expects labels/classes to be in [0, n_classes-1] format\n",
    "def get_mne_epochs(filepath, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    This function reads the EEG data from .mat file and convert it to MNE-Python Compatible epochs\n",
    "    data structure. It takes data from [0, 8] sec range and return it by setting t = 0 at cue onset\n",
    "    i.e. 3 seconds and dropping first two seconds so the output data is in [-1.0, 5.0] sec range. The\n",
    "    Details can be found in the preprocessing section of the attached document\n",
    "    '''\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    eeg_data= mat_data['RawEEGData']\n",
    "    idx_start = fs*t_start      \n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) \n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        epochs.event_id = event_id \n",
    "        epochs.events[:,2] = mat_data['Labels'].ravel() - 1    \n",
    "    return epochs \n",
    "\n",
    "def get_labels(filepath):\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    return mat_data['Labels'].ravel() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (80, 12, 3072) \t Shape of Labels:  (80,)\n"
     ]
    }
   ],
   "source": [
    "epochs, labels = get_mne_epochs(training_files[0], verbose=verbose), get_labels(training_files[0])\n",
    "data = epochs.get_data()\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original data\n",
    "epochs_list_train = []\n",
    "for i in training_files:\n",
    "    epochs_list_train.append(get_mne_epochs(i, verbose=verbose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "https://braindecode.org/auto_examples/plot_mne_dataset_example.html\n",
    "\n",
    "https://braindecode.org/auto_examples/plot_bcic_iv_2a_moabb_trial.html\n",
    "\n",
    "Applying NumpyPreproc to mne.epochs give error related to apply_function implementation: https://github.com/braindecode/braindecode/issues/160\n",
    "\n",
    "can modify the description attribute of datasets by manually passing a pandas dataframe/series and then split accordingly\n",
    "\n",
    "the issue of size mismatch means we are using a different shape input as compared to the built-in models, using EEGNet somehow solves it\n",
    "\n",
    "Target 2 is out of bounds: class labels should be [0, num_classes-1]\n",
    "\n",
    "loading and saving skorch model https://skorch.readthedocs.io/en/stable/user/save_load.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "# convert epochs to braindecode compatible datastructure \n",
    "# 2sec windows with 0.5sec stride\n",
    "window_size = 1024 #50 # 3072\n",
    "window_stride = 128 # 256 # 50\n",
    "\n",
    "windows_datasets = create_from_mne_epochs(\n",
    "    [epochs_list_train[0]], # list of epochs\n",
    "    window_size_samples = window_size,\n",
    "    window_stride_samples = window_stride,\n",
    "    drop_last_window = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = windows_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.datasets[50].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(train_set.datasets)):\n",
    "    labels.extend(train_set.datasets[i].y)\n",
    "labels = np.array(labels) # subtracting 1 as pytorch nll expects labels to be in [0, n_classes-1]\n",
    "train_set.description = pd.DataFrame(data=labels, columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(labels)==0), sum(np.array(labels)==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set.description = pd.DataFrame(data=labels, columns=['labels'])\n",
    "# train_set.description['session'] = None # fill that up later with train/test \n",
    "# df = train_set.description\n",
    "# split_idx = int(len(df)*0.75) # hold-out CV with 75:25 split \n",
    "# df['session'][:split_idx], df['session'][split_idx:] = 'train', 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "..      ...\n",
       "715       0\n",
       "716       0\n",
       "717       0\n",
       "718       0\n",
       "719       0\n",
       "\n",
       "[720 rows x 1 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-31.29383482,  87.77848413, 134.99000647,  60.95198251,\n",
       "       -50.06313685])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_datasets.datasets[0].windows.get_data()[0,0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil.preprocess import exponential_moving_standardize\n",
    "from braindecode.datautil.preprocess import MNEPreproc, NumpyPreproc, preprocess\n",
    "\n",
    "low_cut_hz = 7.  # low cut frequency for filtering\n",
    "high_cut_hz = 32.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "# using NumpyPreproc with exponential_moving_standardize gave error so \n",
    "# I passed a custom callable to MnePreproc\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        epochs._data[i] = exponential_moving_standardize(data[i], \n",
    "                        factor_new=factor_new, init_block_size=init_block_size)\n",
    "    return epochs\n",
    "\n",
    "preprocessors = [\n",
    "    # keep only EEG sensors\n",
    "    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\n",
    "    # convert from volt to microvolt, directly modifying the numpy array, \n",
    "    # I think my data is already in microvolts\n",
    "    # NumpyPreproc(fn=lambda x: x * 1e6),\n",
    "    # bandpass filter\n",
    "    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "    # exponential moving standardization\n",
    "    MNEPreproc(fn=custom_exp_moving_std_fn, factor_new=factor_new,\n",
    "        init_block_size=init_block_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.23328384, 2.57082541, 3.72159681, 4.59938505, 5.14926365])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(windows_datasets, preprocessors)\n",
    "windows_datasets.datasets[0].windows.get_data()[0,0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = train_set[0][0].shape[0]\n",
    "input_window_samples = train_set[0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples = window_size, #input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 1 * 0.05 \n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "batch_size = 8 #64\n",
    "n_epochs = 25\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    #train_split=predefined_split(train_set),  # using valid_set for validation\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
       "  module_=EEGNetv4(\n",
       "    (ensuredims): Ensure4d()\n",
       "    (dimshuffle): Expression(expression=_transpose_to_b_1_c_0) \n",
       "    (conv_temporal): Conv2d(1, 8, kernel_size=(1, 64), stride=(1, 1), padding=(0, 32), bias=False)\n",
       "    (bnorm_temporal): BatchNorm2d(8, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (conv_spatial): Conv2dWithConstraint(8, 16, kernel_size=(12, 1), stride=(1, 1), groups=8, bias=False)\n",
       "    (bnorm_1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (elu_1): Expression(expression=elu) \n",
       "    (pool_1): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
       "    (drop_1): Dropout(p=0.25, inplace=False)\n",
       "    (conv_separable_depth): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), padding=(0, 8), groups=16, bias=False)\n",
       "    (conv_separable_point): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bnorm_2): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (elu_2): Expression(expression=elu) \n",
       "    (pool_2): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
       "    (drop_2): Dropout(p=0.25, inplace=False)\n",
       "    (conv_classifier): Conv2d(16, 2, kernel_size=(1, 32), stride=(1, 1))\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "    (permute_back): Expression(expression=_transpose_1_0) \n",
       "    (squeeze): Expression(expression=squeeze_final_output) \n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5035\u001b[0m        \u001b[32m1.2641\u001b[0m            \u001b[35m0.5000\u001b[0m        \u001b[31m8.6870\u001b[0m  0.0500  4.6160\n",
      "      2            \u001b[36m0.7674\u001b[0m        \u001b[32m0.7391\u001b[0m            \u001b[35m0.5486\u001b[0m        \u001b[31m3.0782\u001b[0m  0.0498  5.5880\n",
      "      3            \u001b[36m0.8455\u001b[0m        0.8920            0.5347        \u001b[31m1.4123\u001b[0m  0.0491  4.9990\n",
      "      4            0.7552        \u001b[32m0.6417\u001b[0m            0.4722        2.4552  0.0481  5.8080\n",
      "      5            0.7917        0.7602            \u001b[35m0.5694\u001b[0m        \u001b[31m1.3458\u001b[0m  0.0467  5.1710\n",
      "      6            0.7396        \u001b[32m0.4640\u001b[0m            0.5417        1.4634  0.0448  4.8490\n",
      "      7            \u001b[36m0.9375\u001b[0m        \u001b[32m0.4465\u001b[0m            \u001b[35m0.5972\u001b[0m        \u001b[31m0.9277\u001b[0m  0.0427  4.8480\n",
      "      8            0.7517        0.4938            0.5417        1.7603  0.0402  5.5680\n",
      "      9            0.6285        \u001b[32m0.4253\u001b[0m            0.5139        1.7298  0.0375  5.2980\n",
      "     10            0.9219        \u001b[32m0.3934\u001b[0m            0.5694        0.9448  0.0346  5.0440\n",
      "     11            0.7656        \u001b[32m0.3866\u001b[0m            0.4931        1.7612  0.0315  4.9780\n",
      "     12            \u001b[36m0.9410\u001b[0m        \u001b[32m0.3203\u001b[0m            \u001b[35m0.6736\u001b[0m        \u001b[31m0.8166\u001b[0m  0.0283  5.0400\n",
      "     13            0.7535        \u001b[32m0.2514\u001b[0m            0.5625        1.6042  0.0250  4.8530\n",
      "     14            0.8559        0.2584            0.5903        1.6984  0.0217  5.0060\n",
      "     15            \u001b[36m0.9896\u001b[0m        \u001b[32m0.2160\u001b[0m            0.5625        1.1566  0.0185  5.0400\n",
      "     16            0.9618        \u001b[32m0.1931\u001b[0m            0.5625        1.1966  0.0154  5.1540\n",
      "     17            0.9184        0.2108            0.5486        1.6540  0.0125  4.9480\n",
      "     18            0.9097        \u001b[32m0.1494\u001b[0m            0.5417        2.0470  0.0098  4.9320\n",
      "     19            0.9392        \u001b[32m0.1179\u001b[0m            0.4722        1.4672  0.0073  4.9190\n",
      "     20            0.9219        0.1281            0.4792        1.7403  0.0052  4.7410\n",
      "     21            0.9844        0.1227            0.5417        1.3955  0.0033  4.8970\n",
      "     22            \u001b[36m0.9983\u001b[0m        \u001b[32m0.0965\u001b[0m            0.5625        1.3079  0.0019  4.8080\n",
      "     23            0.9965        0.1037            0.5417        1.2993  0.0009  4.8290\n",
      "     24            \u001b[36m1.0000\u001b[0m        0.1243            0.5486        1.3327  0.0002  4.8390\n",
      "     25            1.0000        \u001b[32m0.0912\u001b[0m            0.5347        1.3670  0.0000  4.8480\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_set, y=train_set.description.labels, epochs=n_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.9670\u001b[0m        \u001b[32m0.2535\u001b[0m            \u001b[35m0.8194\u001b[0m        \u001b[31m0.5020\u001b[0m  0.0100  6.0250\n",
      "      2            0.7726        \u001b[32m0.2463\u001b[0m            0.6389        1.1504  0.0100  6.1590\n",
      "      3            0.8733        \u001b[32m0.2108\u001b[0m            0.6458        1.1607  0.0098  5.0160\n",
      "      4            \u001b[36m0.9809\u001b[0m        \u001b[32m0.1826\u001b[0m            0.8056        \u001b[31m0.4239\u001b[0m  0.0096  4.8140\n",
      "      5            \u001b[36m0.9878\u001b[0m        \u001b[32m0.1551\u001b[0m            0.7847        0.6272  0.0093  4.8320\n",
      "      6            \u001b[36m0.9913\u001b[0m        \u001b[32m0.1152\u001b[0m            0.7361        0.7034  0.0090  4.7670\n",
      "      7            \u001b[36m1.0000\u001b[0m        0.1287            0.7778        0.5754  0.0085  4.6110\n",
      "      8            0.9878        0.1213            0.7292        0.9005  0.0080  4.8450\n",
      "      9            0.9913        0.1270            0.7431        0.9025  0.0075  4.9960\n",
      "     10            0.9514        \u001b[32m0.0908\u001b[0m            0.6597        1.1948  0.0069  4.9990\n",
      "     11            0.9965        0.0931            0.7222        0.7489  0.0063  5.0770\n",
      "     12            0.9774        \u001b[32m0.0570\u001b[0m            0.6458        1.0880  0.0057  4.7550\n",
      "     13            0.9983        0.0703            0.7153        0.7835  0.0050  4.7080\n",
      "     14            1.0000        \u001b[32m0.0496\u001b[0m            0.7014        0.7956  0.0043  4.8470\n",
      "     15            1.0000        0.0532            0.7014        0.8332  0.0037  4.7990\n",
      "     16            0.9948        0.0550            0.6458        1.2263  0.0031  4.6820\n",
      "     17            1.0000        0.0529            0.7500        0.7464  0.0025  4.7380\n",
      "     18            1.0000        0.0607            0.7431        0.8714  0.0020  4.7830\n",
      "     19            1.0000        \u001b[32m0.0304\u001b[0m            0.7708        0.7933  0.0015  4.9380\n",
      "     20            1.0000        0.0564            0.7361        0.7929  0.0010  4.8610\n",
      "     21            1.0000        0.0599            0.7431        0.7994  0.0007  4.9890\n",
      "     22            1.0000        0.0346            0.7361        0.7903  0.0004  4.6270\n",
      "     23            1.0000        0.0498            0.7431        0.7906  0.0002  5.6620\n",
      "     24            1.0000        0.0459            0.7431        0.7975  0.0000  5.0620\n",
      "     25            1.0000        0.0308            0.7431        0.8005  0.0000  5.5190\n"
     ]
    }
   ],
   "source": [
    "# Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "# in the dataset.\n",
    "clf.fit(train_set, y=train_set.description.labels, epochs=n_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading the model state\n",
    "clf.save_params(f_params='model.pkl', f_optimizer='opt.pkl', f_history='history.json')\n",
    "clf.initialize() # This is important!\n",
    "clf.load_params(f_params='model.pkl', f_optimizer='opt.pkl', f_history='history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 125ms stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "# convert epochs to braindecode compatible datastructure \n",
    "# 2sec windows with 0.125 sec stride\n",
    "window_size = 1024 #50 # 3072\n",
    "window_stride = 64 #256 # 50\n",
    "\n",
    "windows_datasets_list = []\n",
    "for epoch in epochs_list_train:\n",
    "    windows_datasets_list.append(\n",
    "            create_from_mne_epochs(\n",
    "            [epoch.crop(tmin=0.5, tmax=4.5, include_tmax=False)], # [0.5, 4.5] s, expects list of epochs\n",
    "            window_size_samples = window_size,\n",
    "            window_stride_samples = window_stride,\n",
    "            drop_last_window = False\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows_datasets_labels(windows_dataset):\n",
    "    labels = []\n",
    "    for i in range(len(windows_dataset.datasets)):\n",
    "        labels.extend(windows_dataset.datasets[i].y)\n",
    "    return np.array(labels) \n",
    "\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    windows_dataset.description = pd.DataFrame(data=get_windows_datasets_labels(windows_dataset), \n",
    "                                           columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Windows in a Single Dataset:  1360\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Windows in a Single Dataset: \", len(windows_datasets_list[0].description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil.preprocess import exponential_moving_standardize\n",
    "from braindecode.datautil.preprocess import MNEPreproc, NumpyPreproc, preprocess\n",
    "\n",
    "low_cut_hz = 8.  # low cut frequency for filtering\n",
    "high_cut_hz = 32.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        epochs._data[i] = exponential_moving_standardize(data[i], \n",
    "                        factor_new=factor_new, init_block_size=init_block_size)\n",
    "    return epochs\n",
    "\n",
    "preprocessors = [\n",
    "    # keep only EEG sensors\n",
    "    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\n",
    "    # bandpass filter\n",
    "    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "    # exponential moving standardization\n",
    "    MNEPreproc(fn=custom_exp_moving_std_fn, factor_new=factor_new,\n",
    "        init_block_size=init_block_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for windows_dataset in windows_datasets_list: \n",
    "    preprocess(windows_dataset, preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples = window_size, #input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 1 * 0.02 #0.01 \n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "clfs_list = []\n",
    "for i in range(len(epochs_list_train)):\n",
    "    clfs_list.append(\n",
    "        EEGClassifier(\n",
    "                    model,\n",
    "                    criterion=torch.nn.NLLLoss,\n",
    "                    optimizer=torch.optim.AdamW,\n",
    "                    #train_split=predefined_split(train_set),  # using valid_set for validation\n",
    "                    optimizer__lr=lr,\n",
    "                    optimizer__weight_decay=weight_decay,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[\n",
    "                        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "                    ],\n",
    "                    device=device,\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(subject_index=0):\n",
    "    print('\\n', '#'*25, 'Training for Subject:', subject_index+1, '#'*25, '\\n')\n",
    "    dataset = windows_datasets_list[subject_index]\n",
    "    clfs_list[subject_index].fit(dataset, y=dataset.description.labels, epochs=n_epochs);\n",
    "    best_validation_acc = clfs_list[subject_index].callbacks_[4][1].best_score_ # a hack to get best validation accuracy\n",
    "    best_validation_kappa = (2*best_validation_acc)-1\n",
    "    print(\"Best Cross Validation Kappa Score: {:.2f}\".format(best_validation_kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### Training for Subject: 1 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5239\u001b[0m        \u001b[32m0.6587\u001b[0m            \u001b[35m0.5000\u001b[0m        \u001b[31m4.7591\u001b[0m  0.0200  9.0020\n",
      "      2            \u001b[36m0.6517\u001b[0m        \u001b[32m0.3797\u001b[0m            \u001b[35m0.5074\u001b[0m        \u001b[31m2.9087\u001b[0m  0.0199  8.2990\n",
      "      3            \u001b[36m0.7160\u001b[0m        \u001b[32m0.2881\u001b[0m            \u001b[35m0.5221\u001b[0m        3.3227  0.0197  9.0790\n",
      "      4            \u001b[36m0.7647\u001b[0m        \u001b[32m0.2320\u001b[0m            \u001b[35m0.5257\u001b[0m        \u001b[31m2.4932\u001b[0m  0.0192  8.5510\n",
      "      5            \u001b[36m0.9384\u001b[0m        \u001b[32m0.1507\u001b[0m            \u001b[35m0.7096\u001b[0m        \u001b[31m1.3055\u001b[0m  0.0187  8.8320\n",
      "      6            0.5653        \u001b[32m0.1403\u001b[0m            0.5000        4.3148  0.0179  8.6180\n",
      "      7            \u001b[36m0.9550\u001b[0m        0.1484            0.7059        \u001b[31m1.0289\u001b[0m  0.0171  8.7350\n",
      "      8            \u001b[36m0.9789\u001b[0m        0.2000            0.6618        \u001b[31m1.0018\u001b[0m  0.0161  8.4860\n",
      "      9            \u001b[36m0.9945\u001b[0m        \u001b[32m0.1222\u001b[0m            0.5662        1.5762  0.0150  8.6930\n",
      "     10            0.9311        \u001b[32m0.0543\u001b[0m            0.5441        2.5212  0.0138  8.7700\n"
     ]
    }
   ],
   "source": [
    "for subject in range(len(training_files)):\n",
    "    training_function(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "Somehow the problem seems to be with data augmentation as training acc is increasing but validation one isn't. Moreover, we need a large samples not just a hundred to get some results So cropping helped in this regard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
