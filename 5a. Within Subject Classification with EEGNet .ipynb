{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical BCI Challenge-WCCI2020\n",
    "- [website link](https://sites.google.com/view/bci-comp-wcci/?fbclid=IwAR37WLQ_xNd5qsZvktZCT8XJerHhmVb_bU5HDu69CnO85DE3iF0fs57vQ6M)\n",
    "\n",
    "\n",
    " - [Dataset Link](https://github.com/5anirban9/Clinical-Brain-Computer-Interfaces-Challenge-WCCI-2020-Glasgow)\n",
    " \n",
    " \n",
    " - [Braindecode Tutorial](https://braindecode.org/auto_examples/plot_bcic_iv_2a_moabb_trial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n",
    "[Mike Cohen Tutorials link for EEG Preprocessing](https://www.youtube.com/watch?v=uWB5tjhataY&list=PLn0OLiymPak2gDD-VDA90w9_iGDgOOb2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which jupyter file is located\n",
    "data_path = os.path.join(current_folder, 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have modified the labels values from [1, 2] to [0, 1] as pytorch \n",
    "# expects labels/classes to be in [0, n_classes-1] format\n",
    "def get_mne_epochs(filepath, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    This function reads the EEG data from .mat file and convert it to MNE-Python Compatible epochs\n",
    "    data structure. It takes data from [0, 8] sec range and return it by setting t = 0 at cue onset\n",
    "    i.e. 3 seconds and dropping first two seconds so the output data is in [-1.0, 5.0] sec range. The\n",
    "    Details can be found in the preprocessing section of the attached document\n",
    "    '''\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    eeg_data= mat_data['RawEEGData']\n",
    "    idx_start = fs*t_start      \n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 0, 'right-hand': 1} # pytorch expects labels in [0, n_classes-1]\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) \n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        epochs.event_id = event_id \n",
    "        epochs.events[:,2] = mat_data['Labels'].ravel() - 1    \n",
    "    return epochs \n",
    "\n",
    "def get_labels(filepath):\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    return mat_data['Labels'].ravel() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (80, 12, 3072) \t Shape of Labels:  (80,)\n"
     ]
    }
   ],
   "source": [
    "epochs, labels = get_mne_epochs(training_files[0], verbose=verbose), get_labels(training_files[0])\n",
    "data = epochs.get_data()\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original data\n",
    "epochs_list_train = []\n",
    "for i in training_files:\n",
    "    epochs_list_train.append(get_mne_epochs(i, verbose=verbose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Braindecode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time with [0.5, 4.5] sec and 2sec window with 125ms stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil import create_from_mne_epochs\n",
    "\n",
    "# convert epochs to braindecode compatible datastructure \n",
    "# 2sec windows with 0.125 sec stride\n",
    "window_size = 1024 #50 # 3072\n",
    "window_stride = 64 #256 # 50\n",
    "\n",
    "windows_datasets_list = []\n",
    "for epoch in epochs_list_train:\n",
    "    windows_datasets_list.append(\n",
    "            create_from_mne_epochs(\n",
    "            [epoch.crop(tmin=0.5, tmax=4.5, include_tmax=False)], # [0.5, 4.5] s, expects list of epochs\n",
    "            window_size_samples = window_size,\n",
    "            window_stride_samples = window_stride,\n",
    "            drop_last_window = False\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows_datasets_labels(windows_dataset):\n",
    "    labels = []\n",
    "    for i in range(len(windows_dataset.datasets)):\n",
    "        labels.extend(windows_dataset.datasets[i].y)\n",
    "    return np.array(labels) \n",
    "\n",
    "for windows_dataset in windows_datasets_list:\n",
    "    windows_dataset.description = pd.DataFrame(data=get_windows_datasets_labels(windows_dataset), \n",
    "                                           columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Windows in a Single Dataset:  1360\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Windows in a Single Dataset: \", len(windows_datasets_list[0].description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil.preprocess import exponential_moving_standardize\n",
    "from braindecode.datautil.preprocess import MNEPreproc, NumpyPreproc, preprocess\n",
    "\n",
    "low_cut_hz = 8.  # low cut frequency for filtering\n",
    "high_cut_hz = 32.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "def custom_exp_moving_std_fn(epochs, factor_new=factor_new, init_block_size=init_block_size):\n",
    "    data = epochs.get_data()\n",
    "    for i in range(len(data)):\n",
    "        epochs._data[i] = exponential_moving_standardize(data[i], \n",
    "                        factor_new=factor_new, init_block_size=init_block_size)\n",
    "    return epochs\n",
    "\n",
    "preprocessors = [\n",
    "    # keep only EEG sensors\n",
    "    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\n",
    "    # bandpass filter\n",
    "    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
    "    # exponential moving standardization\n",
    "    MNEPreproc(fn=custom_exp_moving_std_fn, factor_new=factor_new,\n",
    "        init_block_size=init_block_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for windows_dataset in windows_datasets_list: \n",
    "    preprocess(windows_dataset, preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "n_epochs = 25 #25 #20 #25 use few epochs for quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGNetv4\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=2\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = windows_datasets_list[0][0][0].shape[0]\n",
    "input_window_samples = windows_datasets_list[0][0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples = window_size, #input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 1 * 0.02 #0.01 \n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "clfs_list = []\n",
    "for i in range(len(epochs_list_train)):\n",
    "    clfs_list.append(\n",
    "        EEGClassifier(\n",
    "                    model,\n",
    "                    criterion=torch.nn.NLLLoss,\n",
    "                    optimizer=torch.optim.AdamW,\n",
    "                    #train_split=predefined_split(train_set),  # using valid_set for validation\n",
    "                    optimizer__lr=lr,\n",
    "                    optimizer__weight_decay=weight_decay,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[\n",
    "                        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "                    ],\n",
    "                    device=device,\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(subject_index=0):\n",
    "    print('\\n', '#'*25, 'Training for Subject:', subject_index+1, '#'*25, '\\n')\n",
    "    dataset = windows_datasets_list[subject_index]\n",
    "    clfs_list[subject_index].fit(dataset, y=dataset.description.labels, epochs=n_epochs);\n",
    "    best_validation_acc = clfs_list[subject_index].callbacks_[4][1].best_score_ # a hack to get best validation accuracy\n",
    "    best_validation_kappa = (2*best_validation_acc)-1\n",
    "    print(\"Best Cross Validation Kappa Score: {:.2f}\".format(best_validation_kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### Training for Subject: 1 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5239\u001b[0m        \u001b[32m0.6587\u001b[0m            \u001b[35m0.5000\u001b[0m        \u001b[31m4.7591\u001b[0m  0.0200  9.0020\n",
      "      2            \u001b[36m0.6517\u001b[0m        \u001b[32m0.3797\u001b[0m            \u001b[35m0.5074\u001b[0m        \u001b[31m2.9087\u001b[0m  0.0199  8.2990\n",
      "      3            \u001b[36m0.7160\u001b[0m        \u001b[32m0.2881\u001b[0m            \u001b[35m0.5221\u001b[0m        3.3227  0.0197  9.0790\n",
      "      4            \u001b[36m0.7647\u001b[0m        \u001b[32m0.2320\u001b[0m            \u001b[35m0.5257\u001b[0m        \u001b[31m2.4932\u001b[0m  0.0192  8.5510\n",
      "      5            \u001b[36m0.9384\u001b[0m        \u001b[32m0.1507\u001b[0m            \u001b[35m0.7096\u001b[0m        \u001b[31m1.3055\u001b[0m  0.0187  8.8320\n",
      "      6            0.5653        \u001b[32m0.1403\u001b[0m            0.5000        4.3148  0.0179  8.6180\n",
      "      7            \u001b[36m0.9550\u001b[0m        0.1484            0.7059        \u001b[31m1.0289\u001b[0m  0.0171  8.7350\n",
      "      8            \u001b[36m0.9789\u001b[0m        0.2000            0.6618        \u001b[31m1.0018\u001b[0m  0.0161  8.4860\n",
      "      9            \u001b[36m0.9945\u001b[0m        \u001b[32m0.1222\u001b[0m            0.5662        1.5762  0.0150  8.6930\n",
      "     10            0.9311        \u001b[32m0.0543\u001b[0m            0.5441        2.5212  0.0138  8.7700\n",
      "     11            0.9430        0.0687            0.6691        1.7588  0.0126  9.5760\n",
      "     12            0.9577        \u001b[32m0.0430\u001b[0m            \u001b[35m0.7426\u001b[0m        1.3381  0.0113  8.2957\n",
      "     13            0.9733        \u001b[32m0.0360\u001b[0m            0.6949        1.4980  0.0100  9.8776\n",
      "     14            0.9485        \u001b[32m0.0302\u001b[0m            0.6434        2.0020  0.0087  9.3530\n",
      "     15            \u001b[36m1.0000\u001b[0m        0.0410            0.6544        1.1031  0.0074  11.0020\n",
      "     16            0.9632        0.0358            0.5184        2.6758  0.0062  11.6134\n",
      "     17            1.0000        \u001b[32m0.0184\u001b[0m            0.6544        1.1441  0.0050  9.9170\n",
      "     18            0.9752        0.0261            0.6397        2.0280  0.0039  8.7560\n",
      "     19            1.0000        0.0270            0.6544        1.2429  0.0029  9.2900\n",
      "     20            1.0000        0.0205            0.6507        1.2457  0.0021  8.7120\n",
      "     21            1.0000        \u001b[32m0.0176\u001b[0m            0.6507        1.2017  0.0013  9.2610\n",
      "     22            1.0000        \u001b[32m0.0158\u001b[0m            0.6360        1.2492  0.0008  9.0830\n",
      "     23            1.0000        0.0165            0.6360        1.2863  0.0003  9.2380\n",
      "     24            1.0000        0.0166            0.6324        1.3253  0.0001  8.5440\n",
      "     25            1.0000        0.0227            0.6250        1.3527  0.0000  7.7970\n",
      "Best Cross Validation Kappa Score: 0.49\n",
      "\n",
      " ######################### Training for Subject: 2 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7601\u001b[0m        \u001b[32m0.4698\u001b[0m            \u001b[35m0.6985\u001b[0m        \u001b[31m0.8153\u001b[0m  0.0200  8.3560\n",
      "      2            0.7040        \u001b[32m0.2298\u001b[0m            0.6213        1.1980  0.0199  9.1150\n",
      "      3            \u001b[36m0.9283\u001b[0m        \u001b[32m0.1936\u001b[0m            \u001b[35m0.8346\u001b[0m        1.0128  0.0197  8.5100\n",
      "      4            0.5699        \u001b[32m0.1877\u001b[0m            0.5000        4.3407  0.0192  8.8190\n",
      "      5            0.7776        \u001b[32m0.1678\u001b[0m            0.5404        1.5577  0.0187  9.2300\n",
      "      6            0.8438        0.1843            0.6728        0.8693  0.0179  9.3140\n",
      "      7            \u001b[36m0.9752\u001b[0m        \u001b[32m0.1383\u001b[0m            0.7941        \u001b[31m0.4877\u001b[0m  0.0171  8.7110\n",
      "      8            \u001b[36m0.9917\u001b[0m        \u001b[32m0.1307\u001b[0m            0.8088        0.6630  0.0161  8.8240\n",
      "      9            0.9871        \u001b[32m0.0855\u001b[0m            0.7721        0.5528  0.0150  8.3220\n",
      "     10            0.9439        \u001b[32m0.0780\u001b[0m            0.7794        1.0438  0.0138  8.9300\n",
      "     11            \u001b[36m0.9982\u001b[0m        \u001b[32m0.0529\u001b[0m            0.8125        0.5767  0.0126  9.6650\n",
      "     12            \u001b[36m0.9991\u001b[0m        0.0616            0.8088        0.6816  0.0113  7.4980\n",
      "     13            0.9816        \u001b[32m0.0323\u001b[0m            0.7794        1.0130  0.0100  7.3670\n",
      "     14            \u001b[36m1.0000\u001b[0m        0.0422            \u001b[35m0.8456\u001b[0m        \u001b[31m0.4549\u001b[0m  0.0087  7.4010\n",
      "     15            1.0000        0.0358            \u001b[35m0.8493\u001b[0m        0.5773  0.0074  7.4360\n",
      "     16            0.9881        \u001b[32m0.0220\u001b[0m            0.7794        1.0923  0.0062  7.3530\n",
      "     17            0.9991        0.0252            0.8015        0.7552  0.0050  7.4710\n",
      "     18            0.9972        0.0278            0.8051        0.7730  0.0039  7.3330\n",
      "     19            0.9963        \u001b[32m0.0114\u001b[0m            0.7868        0.8201  0.0029  7.4510\n",
      "     20            0.9991        0.0141            0.7978        0.8002  0.0021  7.4100\n",
      "     21            1.0000        0.0153            0.8382        \u001b[31m0.4530\u001b[0m  0.0013  7.3530\n",
      "     22            1.0000        0.0176            0.8162        0.5921  0.0008  7.5990\n",
      "     23            1.0000        0.0160            0.8088        0.6493  0.0003  7.4370\n",
      "     24            1.0000        0.0190            0.8162        0.6109  0.0001  7.4060\n",
      "     25            1.0000        0.0127            0.8162        0.5894  0.0000  7.4740\n",
      "Best Cross Validation Kappa Score: 0.70\n",
      "\n",
      " ######################### Training for Subject: 3 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.8180\u001b[0m        \u001b[32m0.6013\u001b[0m            \u001b[35m0.7647\u001b[0m        \u001b[31m0.8321\u001b[0m  0.0200  7.3530\n",
      "      2            \u001b[36m0.9540\u001b[0m        \u001b[32m0.2432\u001b[0m            0.6765        1.5763  0.0199  7.3360\n",
      "      3            \u001b[36m0.9706\u001b[0m        \u001b[32m0.1493\u001b[0m            0.7059        0.9985  0.0197  7.3870\n",
      "      4            0.8290        \u001b[32m0.1313\u001b[0m            0.5221        3.9837  0.0192  7.3650\n",
      "      5            \u001b[36m0.9807\u001b[0m        \u001b[32m0.1274\u001b[0m            0.5515        4.8067  0.0187  7.4080\n",
      "      6            0.9531        0.1336            0.6765        1.6029  0.0179  7.8280\n",
      "      7            \u001b[36m0.9825\u001b[0m        \u001b[32m0.0726\u001b[0m            0.5625        3.8102  0.0171  7.3610\n",
      "      8            0.6434        0.1129            0.5625        2.8449  0.0161  8.0630\n",
      "      9            0.8631        0.1160            0.6287        1.9745  0.0150  8.4700\n",
      "     10            \u001b[36m0.9954\u001b[0m        0.1198            0.6397        2.1081  0.0138  8.2310\n",
      "     11            \u001b[36m0.9972\u001b[0m        \u001b[32m0.0617\u001b[0m            0.6176        2.1406  0.0126  9.2720\n",
      "     12            0.9972        \u001b[32m0.0573\u001b[0m            0.7132        1.1989  0.0113  7.3020\n",
      "     13            0.9807        \u001b[32m0.0454\u001b[0m            0.7426        1.8014  0.0100  7.2930\n",
      "     14            0.9853        \u001b[32m0.0272\u001b[0m            0.6985        2.1824  0.0087  7.5220\n",
      "     15            0.9752        0.0312            0.7647        1.7112  0.0074  7.2010\n",
      "     16            \u001b[36m0.9982\u001b[0m        0.0298            0.7243        1.7876  0.0062  7.1950\n",
      "     17            0.9936        0.0420            0.7537        1.3734  0.0050  7.4150\n",
      "     18            \u001b[36m1.0000\u001b[0m        \u001b[32m0.0249\u001b[0m            \u001b[35m0.7941\u001b[0m        1.2044  0.0039  7.3700\n",
      "     19            0.9982        \u001b[32m0.0210\u001b[0m            0.7169        2.0141  0.0029  7.7530\n",
      "     20            1.0000        0.0228            0.7390        1.8060  0.0021  7.3170\n",
      "     21            1.0000        \u001b[32m0.0168\u001b[0m            0.7316        1.8408  0.0013  7.2660\n",
      "     22            1.0000        \u001b[32m0.0134\u001b[0m            0.7316        1.7666  0.0008  7.2060\n",
      "     23            1.0000        0.0205            0.7169        1.7919  0.0003  7.2240\n",
      "     24            1.0000        \u001b[32m0.0127\u001b[0m            0.7096        1.8178  0.0001  7.2310\n",
      "     25            1.0000        0.0173            0.7059        1.8284  0.0000  7.3310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross Validation Kappa Score: 0.59\n",
      "\n",
      " ######################### Training for Subject: 4 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.8695\u001b[0m        \u001b[32m0.5305\u001b[0m            \u001b[35m0.6471\u001b[0m        \u001b[31m2.0038\u001b[0m  0.0200  18.9708\n",
      "      2            0.5901        \u001b[32m0.2305\u001b[0m            0.5257        2.5732  0.0199  7.4970\n",
      "      3            \u001b[36m0.9862\u001b[0m        \u001b[32m0.1243\u001b[0m            0.6250        2.6868  0.0197  7.2180\n",
      "      4            0.9724        \u001b[32m0.1167\u001b[0m            0.6287        3.2727  0.0192  7.1670\n",
      "      5            0.9853        \u001b[32m0.0963\u001b[0m            \u001b[35m0.6838\u001b[0m        \u001b[31m1.9045\u001b[0m  0.0187  7.4470\n",
      "      6            0.9669        \u001b[32m0.0662\u001b[0m            0.6397        2.0989  0.0179  7.2070\n",
      "      7            0.8290        0.1077            0.5368        5.1095  0.0171  7.7630\n",
      "      8            \u001b[36m1.0000\u001b[0m        0.0818            0.6434        3.1889  0.0161  7.2830\n",
      "      9            0.9991        \u001b[32m0.0610\u001b[0m            0.6397        2.5482  0.0150  8.0560\n",
      "     10            0.9991        \u001b[32m0.0553\u001b[0m            \u001b[35m0.6875\u001b[0m        2.6331  0.0138  8.0170\n",
      "     11            0.9862        0.0625            0.6213        2.4087  0.0126  8.3790\n",
      "     12            0.9733        0.0587            0.5809        3.6242  0.0113  8.4650\n",
      "     13            0.9697        \u001b[32m0.0371\u001b[0m            0.6213        4.0205  0.0100  7.4570\n",
      "     14            0.9936        \u001b[32m0.0277\u001b[0m            0.6360        3.8639  0.0087  7.2160\n",
      "     15            0.9816        \u001b[32m0.0251\u001b[0m            0.6250        4.1725  0.0074  7.2590\n",
      "     16            1.0000        0.0343            0.6544        2.9843  0.0062  7.4190\n",
      "     17            0.9899        \u001b[32m0.0174\u001b[0m            0.6324        3.6156  0.0050  7.2580\n",
      "     18            1.0000        0.0251            0.6581        2.7278  0.0039  7.2250\n",
      "     19            1.0000        \u001b[32m0.0147\u001b[0m            0.6581        2.9644  0.0029  7.1880\n",
      "     20            1.0000        0.0187            0.6507        3.1444  0.0021  9.1530\n",
      "     21            1.0000        0.0222            0.6581        3.1740  0.0013  9.4560\n",
      "     22            1.0000        0.0176            0.6581        3.2578  0.0008  8.4760\n",
      "     23            1.0000        0.0186            0.6507        3.4236  0.0003  8.9690\n",
      "     24            1.0000        0.0169            0.6507        3.4673  0.0001  8.7300\n",
      "     25            1.0000        \u001b[32m0.0135\u001b[0m            0.6471        3.4766  0.0000  8.7360\n",
      "Best Cross Validation Kappa Score: 0.38\n",
      "\n",
      " ######################### Training for Subject: 5 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.8906\u001b[0m        \u001b[32m0.6911\u001b[0m            \u001b[35m0.7243\u001b[0m        \u001b[31m1.2341\u001b[0m  0.0200  33.0507\n",
      "      2            0.6562        \u001b[32m0.2960\u001b[0m            0.6213        \u001b[31m0.9243\u001b[0m  0.0199  8.5250\n",
      "      3            0.7132        \u001b[32m0.2209\u001b[0m            0.6103        \u001b[31m0.8220\u001b[0m  0.0197  9.3480\n",
      "      4            0.5993        \u001b[32m0.1736\u001b[0m            0.5662        1.4807  0.0192  8.7260\n",
      "      5            0.7767        \u001b[32m0.1534\u001b[0m            0.7022        \u001b[31m0.6090\u001b[0m  0.0187  8.4940\n",
      "      6            0.6618        \u001b[32m0.1161\u001b[0m            0.5772        1.5664  0.0179  8.0220\n",
      "      7            0.8438        \u001b[32m0.1038\u001b[0m            \u001b[35m0.7353\u001b[0m        \u001b[31m0.5915\u001b[0m  0.0171  7.7920\n",
      "      8            \u001b[36m0.9899\u001b[0m        \u001b[32m0.0780\u001b[0m            \u001b[35m0.8015\u001b[0m        0.9994  0.0161  8.5550\n",
      "      9            0.9752        0.0911            0.7426        1.2354  0.0150  9.1945\n",
      "     10            0.7941        0.0878            0.6176        1.3235  0.0138  9.0010\n",
      "     11            0.9540        0.1016            0.7426        0.6409  0.0126  9.0470\n",
      "     12            \u001b[36m0.9982\u001b[0m        \u001b[32m0.0776\u001b[0m            0.7978        0.7086  0.0113  9.0150\n",
      "     13            0.9982        \u001b[32m0.0584\u001b[0m            \u001b[35m0.8346\u001b[0m        0.6505  0.0100  9.6290\n",
      "     14            0.9715        \u001b[32m0.0475\u001b[0m            0.6654        0.7493  0.0087  9.3230\n",
      "     15            0.9917        \u001b[32m0.0444\u001b[0m            0.7463        \u001b[31m0.5460\u001b[0m  0.0074  8.5440\n",
      "     16            0.9632        0.0450            0.7721        1.3535  0.0062  9.3660\n",
      "     17            0.9936        \u001b[32m0.0396\u001b[0m            0.6691        0.8728  0.0050  8.6490\n",
      "     18            \u001b[36m1.0000\u001b[0m        \u001b[32m0.0394\u001b[0m            0.7721        0.7754  0.0039  9.8610\n",
      "     19            1.0000        \u001b[32m0.0272\u001b[0m            0.7757        0.7374  0.0029  11.2260\n",
      "     20            1.0000        0.0309            0.7574        0.7530  0.0021  8.6270\n",
      "     21            1.0000        \u001b[32m0.0243\u001b[0m            0.7941        0.9399  0.0013  8.4020\n",
      "     22            1.0000        \u001b[32m0.0241\u001b[0m            0.7721        0.7909  0.0008  9.5800\n",
      "     23            1.0000        0.0250            0.7904        0.9162  0.0003  7.4180\n",
      "     24            1.0000        \u001b[32m0.0219\u001b[0m            0.7904        0.9432  0.0001  7.2330\n",
      "     25            1.0000        \u001b[32m0.0211\u001b[0m            0.7904        0.9582  0.0000  7.4030\n",
      "Best Cross Validation Kappa Score: 0.67\n",
      "\n",
      " ######################### Training for Subject: 6 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.8254\u001b[0m        \u001b[32m0.3363\u001b[0m            \u001b[35m0.7132\u001b[0m        \u001b[31m1.1206\u001b[0m  0.0200  13.6236\n",
      "      2            \u001b[36m0.9265\u001b[0m        \u001b[32m0.0887\u001b[0m            \u001b[35m0.7463\u001b[0m        \u001b[31m0.9075\u001b[0m  0.0199  7.1810\n",
      "      3            0.8796        \u001b[32m0.0835\u001b[0m            \u001b[35m0.7721\u001b[0m        1.2348  0.0197  7.1690\n",
      "      4            0.6847        0.1296            0.6949        2.1864  0.0192  7.9340\n",
      "      5            0.8980        \u001b[32m0.0513\u001b[0m            0.7169        1.1458  0.0187  10.9620\n",
      "      6            \u001b[36m0.9862\u001b[0m        0.0906            0.7206        1.5093  0.0179  9.4540\n",
      "      7            \u001b[36m0.9908\u001b[0m        0.0582            \u001b[35m0.7941\u001b[0m        0.9125  0.0171  7.3260\n",
      "      8            0.9347        0.0704            0.5956        2.5496  0.0161  7.6440\n",
      "      9            0.9835        \u001b[32m0.0396\u001b[0m            0.6213        2.5321  0.0150  8.5730\n",
      "     10            \u001b[36m0.9991\u001b[0m        \u001b[32m0.0351\u001b[0m            0.7537        1.5215  0.0138  9.7830\n",
      "     11            \u001b[36m1.0000\u001b[0m        0.0437            \u001b[35m0.8199\u001b[0m        1.0136  0.0126  9.7670\n",
      "     12            0.9651        \u001b[32m0.0228\u001b[0m            0.5588        2.6780  0.0113  8.9680\n",
      "     13            0.9972        \u001b[32m0.0164\u001b[0m            \u001b[35m0.8529\u001b[0m        \u001b[31m0.7432\u001b[0m  0.0100  9.5700\n",
      "     14            0.9991        0.0265            0.7904        1.0942  0.0087  8.8550\n",
      "     15            1.0000        \u001b[32m0.0124\u001b[0m            0.7316        1.6200  0.0074  9.0330\n",
      "     16            1.0000        0.0145            0.8235        1.1337  0.0062  9.2879\n",
      "     17            1.0000        \u001b[32m0.0089\u001b[0m            0.7169        1.7646  0.0050  9.6249\n",
      "     18            1.0000        \u001b[32m0.0063\u001b[0m            0.8015        1.3766  0.0039  10.2580\n",
      "     19            1.0000        0.0147            0.7353        1.5805  0.0029  8.5400\n",
      "     20            1.0000        0.0150            0.7610        1.4373  0.0021  8.3510\n",
      "     21            1.0000        0.0149            0.7978        1.2822  0.0013  8.0680\n",
      "     22            1.0000        0.0213            0.8199        1.1300  0.0008  7.8650\n",
      "     23            1.0000        \u001b[32m0.0053\u001b[0m            0.8162        1.1552  0.0003  8.9240\n",
      "     24            1.0000        0.0069            0.8199        1.1334  0.0001  8.3730\n",
      "     25            1.0000        \u001b[32m0.0020\u001b[0m            0.8235        1.1221  0.0000  8.5100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross Validation Kappa Score: 0.71\n",
      "\n",
      " ######################### Training for Subject: 7 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.7031\u001b[0m        \u001b[32m1.0620\u001b[0m            \u001b[35m0.5735\u001b[0m        \u001b[31m1.0505\u001b[0m  0.0200  27.2696\n",
      "      2            0.5303        \u001b[32m0.4247\u001b[0m            0.4926        2.1601  0.0199  8.4800\n",
      "      3            \u001b[36m0.9145\u001b[0m        \u001b[32m0.3163\u001b[0m            \u001b[35m0.7574\u001b[0m        \u001b[31m0.5808\u001b[0m  0.0197  9.3040\n",
      "      4            0.5790        \u001b[32m0.2331\u001b[0m            0.5294        1.5632  0.0192  9.6570\n",
      "      5            \u001b[36m0.9449\u001b[0m        \u001b[32m0.2056\u001b[0m            0.6140        1.2266  0.0187  7.8570\n",
      "      6            0.7767        0.2326            0.6066        1.2998  0.0179  9.0460\n",
      "      7            0.9237        \u001b[32m0.1739\u001b[0m            \u001b[35m0.7904\u001b[0m        \u001b[31m0.4986\u001b[0m  0.0171  8.8240\n",
      "      8            0.9283        \u001b[32m0.1647\u001b[0m            0.6066        1.5549  0.0161  9.3680\n",
      "      9            \u001b[36m0.9779\u001b[0m        \u001b[32m0.1552\u001b[0m            0.6434        1.0479  0.0150  8.8460\n",
      "     10            \u001b[36m0.9871\u001b[0m        \u001b[32m0.1051\u001b[0m            \u001b[35m0.7941\u001b[0m        0.5055  0.0138  8.7470\n",
      "     11            0.9017        \u001b[32m0.0848\u001b[0m            0.6728        0.9555  0.0126  9.5940\n",
      "     12            0.8612        \u001b[32m0.0804\u001b[0m            0.5551        2.3000  0.0113  9.6600\n",
      "     13            0.9191        0.0900            0.5735        2.3027  0.0100  9.9330\n",
      "     14            \u001b[36m0.9963\u001b[0m        \u001b[32m0.0734\u001b[0m            0.6912        0.8030  0.0087  10.2360\n",
      "     15            0.9467        \u001b[32m0.0583\u001b[0m            0.7243        0.6987  0.0074  9.4620\n",
      "     16            \u001b[36m0.9991\u001b[0m        \u001b[32m0.0433\u001b[0m            0.6691        0.9103  0.0062  9.1010\n",
      "     17            0.9945        0.0466            \u001b[35m0.8493\u001b[0m        \u001b[31m0.4413\u001b[0m  0.0050  9.5310\n",
      "     18            \u001b[36m1.0000\u001b[0m        \u001b[32m0.0424\u001b[0m            0.8309        0.4494  0.0039  7.4990\n",
      "     19            0.9991        \u001b[32m0.0319\u001b[0m            0.7096        0.8296  0.0029  7.4670\n",
      "     20            1.0000        \u001b[32m0.0264\u001b[0m            0.8456        \u001b[31m0.4168\u001b[0m  0.0021  7.4480\n",
      "     21            1.0000        0.0353            0.7831        0.5961  0.0013  7.3770\n",
      "     22            1.0000        \u001b[32m0.0244\u001b[0m            0.7463        0.7031  0.0008  7.2560\n",
      "     23            1.0000        0.0291            0.7390        0.7355  0.0003  7.3470\n",
      "     24            1.0000        0.0265            0.7610        0.6817  0.0001  7.3220\n",
      "     25            1.0000        0.0307            0.7574        0.6819  0.0000  7.2570\n",
      "Best Cross Validation Kappa Score: 0.70\n",
      "\n",
      " ######################### Training for Subject: 8 ######################### \n",
      "\n",
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.7757\u001b[0m        \u001b[32m0.8560\u001b[0m            \u001b[35m0.8235\u001b[0m        \u001b[31m0.4150\u001b[0m  0.0200  27.0802\n",
      "      2            \u001b[36m0.8097\u001b[0m        \u001b[32m0.3897\u001b[0m            0.8199        0.4806  0.0199  7.2690\n",
      "      3            \u001b[36m0.9108\u001b[0m        \u001b[32m0.3290\u001b[0m            \u001b[35m0.8382\u001b[0m        0.5290  0.0197  7.9390\n",
      "      4            0.8658        \u001b[32m0.2566\u001b[0m            0.7721        1.0552  0.0192  9.8247\n",
      "      5            0.6912        \u001b[32m0.2539\u001b[0m            0.6324        1.7032  0.0187  9.3120\n",
      "      6            0.5000        \u001b[32m0.2298\u001b[0m            0.5000        5.2227  0.0179  8.8950\n",
      "      7            0.5092        \u001b[32m0.2076\u001b[0m            0.5221        3.9916  0.0171  8.7480\n",
      "      8            0.7730        \u001b[32m0.1368\u001b[0m            0.6397        1.6309  0.0161  8.0290\n",
      "      9            0.8088        0.1518            0.6434        1.7144  0.0150  7.6130\n",
      "     10            \u001b[36m0.9219\u001b[0m        \u001b[32m0.1349\u001b[0m            \u001b[35m0.8603\u001b[0m        0.4677  0.0138  7.7940\n",
      "     11            \u001b[36m0.9825\u001b[0m        0.1468            \u001b[35m0.8860\u001b[0m        0.4263  0.0126  7.4970\n",
      "     12            \u001b[36m0.9917\u001b[0m        \u001b[32m0.1127\u001b[0m            0.8750        0.4540  0.0113  8.2970\n",
      "     13            \u001b[36m0.9963\u001b[0m        \u001b[32m0.0841\u001b[0m            0.8309        0.5388  0.0100  7.8080\n",
      "     14            0.9844        0.0927            0.8419        0.5432  0.0087  8.4850\n",
      "     15            0.9945        \u001b[32m0.0829\u001b[0m            0.8640        0.5950  0.0074  9.0810\n",
      "     16            0.9724        \u001b[32m0.0725\u001b[0m            0.7316        1.0324  0.0062  8.8130\n",
      "     17            \u001b[36m0.9991\u001b[0m        \u001b[32m0.0497\u001b[0m            0.8309        0.6303  0.0050  10.1662\n",
      "     18            0.9991        0.0532            0.8860        0.4401  0.0039  7.8490\n",
      "     19            0.9844        0.0510            0.8493        0.4622  0.0029  7.7670\n",
      "     20            \u001b[36m1.0000\u001b[0m        0.0511            0.8787        0.5020  0.0021  8.6940\n",
      "     21            1.0000        \u001b[32m0.0383\u001b[0m            0.8529        0.5273  0.0013  8.4770\n",
      "     22            0.9991        0.0385            0.8640        0.4508  0.0008  7.6870\n",
      "     23            0.9991        0.0454            0.8640        0.4594  0.0003  8.0780\n",
      "     24            0.9991        \u001b[32m0.0365\u001b[0m            0.8676        0.4700  0.0001  8.3600\n",
      "     25            0.9991        0.0433            0.8676        0.4717  0.0000  7.5730\n",
      "Best Cross Validation Kappa Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "for subject in range(len(training_files)):\n",
    "    training_function(subject)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
