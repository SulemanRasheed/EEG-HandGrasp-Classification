{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical BCI Challenge-WCCI2020\n",
    "- [website link](https://sites.google.com/view/bci-comp-wcci/?fbclid=IwAR37WLQ_xNd5qsZvktZCT8XJerHhmVb_bU5HDu69CnO85DE3iF0fs57vQ6M)\n",
    "\n",
    "\n",
    " - [Dataset Link](https://github.com/5anirban9/Clinical-Brain-Computer-Interfaces-Challenge-WCCI-2020-Glasgow)\n",
    " \n",
    " \n",
    " - [FBCSP Github Repo Link](https://github.com/jesus-333/FBCSP-Python)\n",
    " \n",
    "I have changed the source code to give cohen's kappa score instead of accuracy as an evaluation measure and I have also made a few other small changes as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FBCSP.FBCSP_V4 import FBCSP_V4 as FBCSP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from mne.decoding import CSP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False                    # global variable to suppress output display of MNE functions\n",
    "mne.set_log_level(verbose=verbose) # to suppress large info outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_clf = False # control output of FBCSP function\n",
    "freqs_band = np.linspace(8, 32, 7) # filter bank choice\n",
    "cv = 10\n",
    "train_ratio = 0.75 # 75:25 for trian-valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None  # for multicore parallel processing, set it to 1 if cause memory issues, for full utilization set to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Conversion to MNE Datatypes\n",
    "[Mike Cohen Tutorials link for EEG Preprocessing](https://www.youtube.com/watch?v=uWB5tjhataY&list=PLn0OLiymPak2gDD-VDA90w9_iGDgOOb2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = globals()['_dh'][0]  # a hack to get path of current folder in which juptyter file is located\n",
    "data_path = os.path.join(current_folder, 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loadedtraining_files   = glob.glob(data_path + '/*T.mat')\n",
    "len(training_files)     # if  return zero,then no file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mne_epochs(filepath, verbose=verbose, t_start=2, fs=512, mode='train'):\n",
    "    '''\n",
    "    This function reads the EEG data from .mat file and convert it to MNE-Python Compatible epochs\n",
    "    data structure. It takes data from [0, 8] sec range and return it by setting t = 0 at cue onset\n",
    "    i.e. 3 seconds and dropping first two seconds so the output data is in [-1.0, 5.0] sec range. The\n",
    "    Details can be found in the preprocessing section of the attached document\n",
    "    '''\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    eeg_data= mat_data['RawEEGData']\n",
    "    idx_start = fs*t_start      \n",
    "    eeg_data = eeg_data[:, :, idx_start:]\n",
    "    event_id = {'left-hand': 1, 'right-hand': 2}\n",
    "    channel_names = ['F3', 'FC3', 'C3', 'CP3', 'P3', 'FCz', 'CPz', 'F4', 'FC4', 'C4', 'CP4', 'P4']\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=fs, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=t_start-3.0)\n",
    "    epochs.set_montage('standard_1020')\n",
    "    epochs.filter(1., None) \n",
    "    epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n",
    "    \n",
    "    if mode == 'train': # this in only applicable for training data\n",
    "        epochs.event_id = event_id\n",
    "        epochs.events[:,2] = mat_data['Labels'].ravel()    \n",
    "    return epochs \n",
    "\n",
    "def get_labels(filepath):\n",
    "    mat_data = loadmat(filepath) # read .mat file\n",
    "    return mat_data['Labels'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG Data:  (80, 12, 3072) \t Shape of Labels:  (80,)\n"
     ]
    }
   ],
   "source": [
    "epochs, labels = get_mne_epochs(training_files[0], verbose=verbose), get_labels(training_files[0])\n",
    "data = epochs.get_data()\n",
    "print('Shape of EEG Data: ', data.shape, '\\t Shape of Labels: ', labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original data\n",
    "epochs_list_train = []\n",
    "for i in training_files:\n",
    "    epochs_list_train.append(get_mne_epochs(i, verbose=verbose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandpass filtering of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in epochs_list_train:\n",
    "    epoch.filter(7.0, 32.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBCSP \n",
    "The class must receive in input with the initialization a training set inside a dictionary. The keys of the dictionary must be the label of the two class and each element must be a numpy matrix of dimension \"n. trials x n. channels x n.samples\". The class must also receive the frequency sampling of the signal.\n",
    "\n",
    "FBCSP function original has a built-in random splitting so I didn't do a manual splitting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs_list_train[0]\n",
    "data, labels = epochs.get_data(), epochs.events[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'left-hand':  epochs['left-hand'].get_data()[:,:,256+512:-256], # [0.5, 4.5] sec data\n",
    "             'right-hand': epochs['right-hand'].get_data()[:,:,256+512:-256]}\n",
    "fs = epochs.info['sfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FBCSP with LDA ---------------\n",
      "Features used for classification:  8\n",
      "Score on Training set:  0.9\n",
      "Score on Validation set:  0.797979797979798 \n",
      "\n",
      "--------------- FBCSP with Linear SVM ---------------\n",
      "Features used for classification:  8\n",
      "Score on Training set:  0.9\n",
      "Score on Validation set:  0.6875 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_scores_lda = []\n",
    "valid_scores_svm = []\n",
    "print('-'*15, 'FBCSP with LDA', '-'*15)\n",
    "fbcsp_clf_lda = FBCSP(data_dict, fs, freqs_band=freqs_band, classifier=lda(), \n",
    "                    train_ratio=train_ratio)\n",
    "valid_scores_lda.append(fbcsp_clf_lda.valid_score)\n",
    "print('-'*15, 'FBCSP with Linear SVM', '-'*15)\n",
    "fbcsp_clf_svm = FBCSP(data_dict, fs, freqs_band=freqs_band, classifier=LinearSVC(), \n",
    "                    train_ratio=train_ratio)\n",
    "valid_scores_svm.append(fbcsp_clf_svm.valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporating cross validation\n",
    "valid_scores_lda = []\n",
    "valid_scores_svm = []\n",
    "\n",
    "for _ in range(cv):\n",
    "    fbcsp_clf_lda = FBCSP(data_dict, fs, freqs_band=freqs_band, classifier=lda(), \n",
    "                        train_ratio=0.75, print_var=verbose_clf)\n",
    "    valid_scores_lda.append(fbcsp_clf_lda.valid_score)\n",
    "    \n",
    "    fbcsp_clf_svm = FBCSP(data_dict, fs, freqs_band=freqs_band, classifier=LinearSVC(), \n",
    "                        train_ratio=0.75, print_var=verbose_clf)\n",
    "    valid_scores_svm.append(fbcsp_clf_svm.valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBCSP-LDA Cross Validation Score: 0.7217547114539595\n",
      "FBCSP-SVM Cross Validation Score: 0.722064737136882\n"
     ]
    }
   ],
   "source": [
    "print(\"FBCSP-LDA Cross Validation Score:\", np.mean(valid_scores_lda))\n",
    "print(\"FBCSP-SVM Cross Validation Score:\", np.mean(valid_scores_svm)) \n",
    "# we aren't doing grid search here so wouldn't take max score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's Training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(subject_index=0):\n",
    "    # this time training function trains on whole training set\n",
    "    print('-'*25, 'Training for Subject:', subject_index+1, '-'*25)\n",
    "    epochs = epochs_list_train[subject_index]\n",
    "    data_dict = {'left-hand':  epochs['left-hand'].get_data()[:,:,256+512:-256], # [0.5, 4.5] sec data\n",
    "             'right-hand': epochs['right-hand'].get_data()[:,:,256+512:-256]}\n",
    "    fs = epochs.info['sfreq']\n",
    "    labels = epochs.events[:,-1]\n",
    "    valid_scores_lda = []\n",
    "    valid_scores_svm = []\n",
    "\n",
    "    for _ in range(cv):\n",
    "        fbcsp_clf_lda = FBCSP(data_dict, fs, freqs_band=freqs_band, classifier=lda(), \n",
    "                            train_ratio=train_ratio, print_var=verbose_clf)\n",
    "        valid_scores_lda.append(fbcsp_clf_lda.valid_score)\n",
    "        \n",
    "        fbcsp_clf_svm = FBCSP(data_dict, fs, freqs_band=freqs_band, classifier=LinearSVC(), \n",
    "                            train_ratio=train_ratio, print_var=verbose_clf)\n",
    "        valid_scores_svm.append(fbcsp_clf_svm.valid_score)\n",
    "        \n",
    "    print(\"FBCSP-LDA Cross Validation Score: {:.2f}\".format(np.mean(valid_scores_lda)))\n",
    "    print(\"FBCSP-SVM Cross Validation Score: {:.2f}\".format(np.mean(valid_scores_svm))) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training for Subject: 1 -------------------------\n",
      "FBCSP-LDA Cross Validation Score: 0.71\n",
      "FBCSP-SVM Cross Validation Score: 0.79\n",
      "\n",
      "------------------------- Training for Subject: 2 -------------------------\n",
      "FBCSP-LDA Cross Validation Score: 0.73\n",
      "FBCSP-SVM Cross Validation Score: 0.79\n",
      "\n",
      "------------------------- Training for Subject: 3 -------------------------\n",
      "FBCSP-LDA Cross Validation Score: 0.64\n",
      "FBCSP-SVM Cross Validation Score: 0.62\n",
      "\n",
      "------------------------- Training for Subject: 4 -------------------------\n",
      "FBCSP-LDA Cross Validation Score: 0.77\n",
      "FBCSP-SVM Cross Validation Score: 0.64\n",
      "\n",
      "------------------------- Training for Subject: 5 -------------------------\n",
      "FBCSP-LDA Cross Validation Score: 0.75\n",
      "FBCSP-SVM Cross Validation Score: 0.67\n",
      "\n",
      "------------------------- Training for Subject: 6 -------------------------\n",
      "FBCSP-LDA Cross Validation Score: 0.77\n",
      "FBCSP-SVM Cross Validation Score: 0.78\n",
      "\n",
      "------------------------- Training for Subject: 7 -------------------------\n",
      "FBCSP-LDA Cross Validation Score: 0.56\n",
      "FBCSP-SVM Cross Validation Score: 0.51\n",
      "\n",
      "------------------------- Training for Subject: 8 -------------------------\n",
      "FBCSP-LDA Cross Validation Score: 0.80\n",
      "FBCSP-SVM Cross Validation Score: 0.77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subject in range(len(training_files)):\n",
    "    training_function(subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Winners for individual subjects\n",
    "- FBCSP-LDA:  3, 4, 5, 7, 8\n",
    "- FBCSP-SVM:  All others"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
